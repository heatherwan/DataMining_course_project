{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_coefs(coefs, names = None, sort = False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name)\n",
    "                                   for coef, name in lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv', sep = '|')\n",
    "test_data = pd.read_csv('data/test.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "## normalize w/ encode \n",
    "y = train_data['fraud']\n",
    "X = train_data.drop(columns=['fraud']).astype(float)\n",
    "X_all = X.append(test_data, sort=False)\n",
    "X_all= pd.get_dummies(X_all, columns=['trustLevel'], prefix='trustLevel')\n",
    "X_norm_encode = pd.DataFrame(MinMaxScaler().fit_transform(X_all), columns=X_all.columns, index=X_all.index)\n",
    "print(X_norm_encode.shape)\n",
    "X_train_norm_enc = X_norm_encode.iloc[:1879,:]\n",
    "X_test_norm_enc = X_norm_encode.iloc[1879:,:]\n",
    "# print(X_train_norm_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 9)\n"
     ]
    }
   ],
   "source": [
    "## normalized w/o encode \n",
    "train_data = pd.read_csv('data/train.csv', sep = '|')\n",
    "test_data = pd.read_csv('data/test.csv', sep = '|')\n",
    "y = train_data['fraud']\n",
    "X = train_data.drop(columns=['fraud']).astype(float)\n",
    "X_all = X.append(test_data, sort=False)\n",
    "X_norm = pd.DataFrame(MinMaxScaler().fit_transform(X_all), columns=X_all.columns, index=X_all.index)\n",
    "print(X_norm.shape)\n",
    "X_train_norm = X_norm.iloc[:1879,:]\n",
    "X_test_norm = X_norm.iloc[1879:,:]\n",
    "# print(X_train_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4399, 'scannedLineItemsPerSecond'),\n",
       " (0.2253, 'lineItemVoidsPerPosition'),\n",
       " (0.2159, 'trustLevel'),\n",
       " (0.1053, 'valuePerSecond'),\n",
       " (0.0933, 'totalScanTimeInSeconds'),\n",
       " (0.0716, 'lineItemVoids'),\n",
       " (0.0593, 'scansWithoutRegistration'),\n",
       " (0.0146, 'grandTotal'),\n",
       " (0.003, 'quantityModifications')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature extraction with linear regression\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train_norm, y)\n",
    "# Summarize scores\n",
    "sorted(zip(map(lambda x: round(x, 4), abs(regr.coef_)), X_train_norm.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==chi2==\n",
      "46.72 trustLevel\n",
      "3.78 totalScanTimeInSeconds\n",
      "3.28 lineItemVoidsPerPosition\n",
      "2.07 scansWithoutRegistration\n",
      "1.5 lineItemVoids\n",
      "0.12 valuePerSecond\n",
      "0.04 scannedLineItemsPerSecond\n",
      "0.0 quantityModifications\n",
      "0.0 grandTotal\n",
      "==f_classif==\n",
      "213.78 trustLevel\n",
      "23.17 totalScanTimeInSeconds\n",
      "15.37 lineItemVoidsPerPosition\n",
      "10.37 scansWithoutRegistration\n",
      "7.6 lineItemVoids\n",
      "1.57 valuePerSecond\n",
      "1.0 scannedLineItemsPerSecond\n",
      "0.0 quantityModifications\n",
      "0.0 grandTotal\n",
      "==mutual_info_classif==\n",
      "0.07 trustLevel\n",
      "0.03 scannedLineItemsPerSecond\n",
      "0.03 lineItemVoidsPerPosition\n",
      "0.01 totalScanTimeInSeconds\n",
      "0.01 scansWithoutRegistration\n",
      "0.01 quantityModifications\n",
      "0.0 valuePerSecond\n",
      "0.0 lineItemVoids\n",
      "0.0 grandTotal\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction with selectKBest\n",
    "score = {'chi2': chi2, 'f_classif':f_classif, 'mutual_info_classif':mutual_info_classif }\n",
    "    \n",
    "for k, v in score.items():\n",
    "    print(f'=={k}==')\n",
    "    test = SelectKBest(score_func=v, k=3) # choose top3\n",
    "    fit = test.fit(X_train_norm, y)\n",
    "    # Summarize scores\n",
    "    for i, j in sorted(zip(map(lambda x: round(x, 2), fit.scores_), X_train_norm.columns), reverse=True):\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.72 trustLevel\n",
      "3.78 totalScanTimeInSeconds\n",
      "3.28 lineItemVoidsPerPosition\n",
      "2.07 scansWithoutRegistration\n",
      "1.5 lineItemVoids\n",
      "0.12 valuePerSecond\n",
      "0.04 scannedLineItemsPerSecond\n",
      "0.0 quantityModifications\n",
      "0.0 grandTotal\n",
      "213.78 trustLevel\n",
      "23.17 totalScanTimeInSeconds\n",
      "15.37 lineItemVoidsPerPosition\n",
      "10.37 scansWithoutRegistration\n",
      "7.6 lineItemVoids\n",
      "1.57 valuePerSecond\n",
      "1.0 scannedLineItemsPerSecond\n",
      "0.0 quantityModifications\n",
      "0.0 grandTotal\n",
      "0.07 trustLevel\n",
      "0.03 scannedLineItemsPerSecond\n",
      "0.03 lineItemVoidsPerPosition\n",
      "0.0 valuePerSecond\n",
      "0.0 totalScanTimeInSeconds\n",
      "0.0 scansWithoutRegistration\n",
      "0.0 quantityModifications\n",
      "0.0 lineItemVoids\n",
      "0.0 grandTotal\n"
     ]
    }
   ],
   "source": [
    "feature_KBest(3, X_train_norm, y, chi2, f_classif, mutual_info_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic\n",
      "1.9286 totalScanTimeInSeconds\n",
      "1.2393 scansWithoutRegistration\n",
      "1.1487 lineItemVoids\n",
      "0.3701 grandTotal\n",
      "0.1049 quantityModifications\n",
      "0.0038 scannedLineItemsPerSecond\n",
      "-0.0365 valuePerSecond\n",
      "-3.099 lineItemVoidsPerPosition\n",
      "-6.5162 trustLevel\n",
      "RFE\n",
      "Num Features: 3\n",
      "Feature Ranking: [1 1 4 3 2 5 7 6 1]\n",
      "1 lineItemVoidsPerPosition\n",
      "1 totalScanTimeInSeconds\n",
      "1 trustLevel\n",
      "2 scansWithoutRegistration\n",
      "3 lineItemVoids\n",
      "4 grandTotal\n",
      "5 quantityModifications\n",
      "6 valuePerSecond\n",
      "7 scannedLineItemsPerSecond\n",
      "ridge\n",
      "0.2182 lineItemVoidsPerPosition\n",
      "0.2146 trustLevel\n",
      "0.0905 totalScanTimeInSeconds\n",
      "0.0703 lineItemVoids\n",
      "0.0588 scansWithoutRegistration\n",
      "0.0424 scannedLineItemsPerSecond\n",
      "0.0192 valuePerSecond\n",
      "0.0139 grandTotal\n",
      "0.0027 quantityModifications\n",
      "Lasso\n",
      "0.0 valuePerSecond\n",
      "0.0 trustLevel\n",
      "0.0 totalScanTimeInSeconds\n",
      "0.0 scansWithoutRegistration\n",
      "0.0 scannedLineItemsPerSecond\n",
      "0.0 quantityModifications\n",
      "0.0 lineItemVoidsPerPosition\n",
      "0.0 lineItemVoids\n",
      "0.0 grandTotal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {'logistic': LogisticRegression(solver='lbfgs', max_iter=300), 'RFE': RFE(model, 3), \n",
    "         'ridge': Ridge(alpha=1.0), 'Lasso': Lasso()}\n",
    "for k, v in models.items():\n",
    "    print(k)\n",
    "    fit = v.fit(X_train_norm, y)\n",
    "    if k == 'RFE':\n",
    "        print(\"Num Features: %s\" % (fit.n_features_))\n",
    "        print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
    "        for i, j in sorted(zip(fit.ranking_, X_train_norm.columns), reverse=False):\n",
    "            print(i,j)\n",
    "            \n",
    "    elif k == 'logistic':\n",
    "        for i, j in sorted(zip(map(lambda x: round(x, 4), fit.coef_.reshape(-1)), X_train_norm.columns), reverse=True):\n",
    "            print(i,j)\n",
    "    else:\n",
    "        for i, j in sorted(zip(map(lambda x: round(x, 4), abs(fit.coef_)), X_train_norm.columns), reverse=True):\n",
    "            print(i,j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2276, 'scannedLineItemsPerSecond'),\n",
       " (0.2035, 'totalScanTimeInSeconds'),\n",
       " (0.1965, 'trustLevel'),\n",
       " (0.1299, 'lineItemVoidsPerPosition'),\n",
       " (0.0835, 'lineItemVoids'),\n",
       " (0.0598, 'valuePerSecond'),\n",
       " (0.049, 'scansWithoutRegistration'),\n",
       " (0.0346, 'grandTotal'),\n",
       " (0.0158, 'quantityModifications')]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature extraction with randomforest\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train_norm, y)\n",
    "sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), X_train_norm.columns), reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
