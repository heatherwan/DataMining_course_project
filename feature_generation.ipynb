{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different perspective\n",
    "1. PCA\n",
    "2. manual\n",
    "   - encode trustLevel\n",
    "   - delete 'valuePerSecond', 'scannedLineItemsPerSecond', 'lineItemVoidsPerPosition'\n",
    "   - generate no. item = totalScanTimeInSeconds * scannedLineItemsPerSecond\n",
    "3. automatic generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for test\n",
    "prepare different input dataset and test at 10-fold stratified cross validation set\n",
    "1. train_data (raw data)\n",
    "2. X_train_norm_enc data (normalized and encode)\n",
    "3. X_train_manual (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from classifiers import *\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 1879 entries and 10 features\n",
      "Test set has 498121 entries and 9 features\n",
      "(1879, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train.csv', sep = '|')\n",
    "test_data = pd.read_csv('data/test.csv', sep = '|')\n",
    "print(f'Train set has {train_data.shape[0]} entries and {train_data.shape[1]} features')\n",
    "print(f'Test set has {test_data.shape[0]} entries and {test_data.shape[1]} features')\n",
    "\n",
    "y = train_data['fraud']\n",
    "X = train_data.drop(columns=['fraud']).astype(float)\n",
    "fit_minmax = MinMaxScaler()\n",
    "X_encode = pd.get_dummies(X, columns=['trustLevel'], prefix='trustLevel')\n",
    "X_train_norm_enc = pd.DataFrame(fit_minmax.fit_transform(X_encode), columns=X_encode.columns, index=X_encode.index)\n",
    "print(X_train_norm_enc.shape)\n",
    "X_test_encode = pd.get_dummies(test_data, columns=['trustLevel'], prefix='trustLevel')\n",
    "X_test_norm_enc = pd.DataFrame(fit_minmax.transform(X_test_encode), columns=X_test_encode.columns, index=X_test_encode.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual delete and create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1879, 12)\n",
      "(498121, 12)\n"
     ]
    }
   ],
   "source": [
    "## delete correlate features\n",
    "X_manual = X.assign(no_item = X.totalScanTimeInSeconds* X.scannedLineItemsPerSecond)\\\n",
    "                     .drop(columns=['valuePerSecond', 'scannedLineItemsPerSecond', 'lineItemVoidsPerPosition'])\n",
    "fit_minmax = MinMaxScaler()\n",
    "X_manual_encode = pd.get_dummies(X_manual, columns=['trustLevel'], prefix='trustLevel')\n",
    "X_train_manual = pd.DataFrame(fit_minmax.fit_transform(X_manual_encode), columns=X_manual_encode.columns, index=X_manual_encode.index)\n",
    "print(X_train_manual.shape)\n",
    "\n",
    "X_test = test_data.assign(no_item = test_data.totalScanTimeInSeconds* test_data.scannedLineItemsPerSecond)\\\n",
    "                     .drop(columns=['valuePerSecond', 'scannedLineItemsPerSecond', 'lineItemVoidsPerPosition'])\n",
    "X_test_encode = pd.get_dummies(X_test, columns=['trustLevel'], prefix='trustLevel')\n",
    "X_test_manual = pd.DataFrame(fit_minmax.transform(X_test_encode), columns=X_test_encode.columns, index=X_test_encode.index)\n",
    "print(X_test_manual.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_for_test(X,y):\n",
    "    \"\"\"\n",
    "    test code with 10-fold stratified cross validation\n",
    "    parameters\n",
    "    X: trainset features after generation\n",
    "    y: trainset y label\n",
    "    \"\"\"\n",
    "    evaluate_classification(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nerest Neighbors: test core = -710 \n",
      "Linear SVM: test core = -520 \n",
      "RBF SVM: test core = -610 \n",
      "Logistic Regression: test core = -630 \n",
      "Decision Tree: test core = -785 \n",
      "Neural Net: test core = -505 \n",
      "Random Forest: test core = -155 \n",
      "AdaBoost: test core = -65 \n",
      "XGBoost: test core = -60 \n"
     ]
    }
   ],
   "source": [
    "code_for_test(X_train_norm_enc, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nerest Neighbors: test core = -65 \n",
      "Linear SVM: test core = -520 \n",
      "RBF SVM: test core = 225 \n",
      "Logistic Regression: test core = 205 \n",
      "Decision Tree: test core = -260 \n",
      "Neural Net: test core = 170 \n",
      "Random Forest: test core = 175 \n",
      "AdaBoost: test core = 135 \n",
      "XGBoost: test core = 80 \n"
     ]
    }
   ],
   "source": [
    "code_for_test(X_train_manual, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
